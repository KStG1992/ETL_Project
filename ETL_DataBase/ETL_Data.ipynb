{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iporting Dependencies\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from Resources.config import sqlpass\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting airports.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the csv files in\n",
    "airport = \"Resources/airports.csv\"\n",
    "\n",
    "#create df for airports\n",
    "airport_df = pd.read_csv(airport)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming airports.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean the airport df to only read the state of NY\n",
    "NY_airports = airport_df.loc[airport_df['iso_region'] == 'US-NY']\n",
    "\n",
    "\n",
    "#remove columns with duplicate information or blank\n",
    "cleaned = NY_airports.drop(columns=['continent','home_link', 'wikipedia_link','keywords'], axis=1)\n",
    "\n",
    "#remove all rows that have NaN in 'iata_code' to get rid of heleports, local hangers, ect...\n",
    "airport_cleaned= cleaned[pd.notnull(cleaned['iata_code'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting flights.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the csv files in\n",
    "flights = \"Resources/flights_sample1.csv\"\n",
    "\n",
    "#create df for flights\n",
    "flights_df = pd.read_csv(flights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming flights.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean the flight data by removing unnecessary columns\n",
    "cleaned_flights = flights_df.drop(columns=['TAXI_OUT', 'WHEELS_OFF','WHEELS_ON', 'TAXI_IN', ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove all origin airport or destination airports that are not in the airports dataframe by iata_code\n",
    "NY_flights = cleaned_flights[(cleaned_flights['ORIGIN_AIRPORT'].isin(airport_cleaned['iata_code'])) | (cleaned_flights['DESTINATION_AIRPORT'].isin(airport_cleaned['iata_code']))] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new Date column\n",
    "NY_flights['DATE'] = \"\"\n",
    "\n",
    "#Merge Year, Month and Day columns together \n",
    "\n",
    "NY_flights[\"DATE\"]=NY_flights.apply(lambda x:'%s-%s-%s' % (x['YEAR'],x['MONTH'], x['DAY']),axis=1)\n",
    "#convert date column to datetime format\n",
    "NY_flights['DATE'] = pd.to_datetime(NY_flights['DATE'])\n",
    "\n",
    "#Drop the Year, Month and Day columns as they are now unnecessary\n",
    "NY_flights.drop(columns=['YEAR', 'MONTH','DAY'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorder the columns\n",
    "NY_flights = NY_flights[['DATE', 'DAY_OF_WEEK', 'AIRLINE', 'FLIGHT_NUMBER',\\\n",
    "                        'TAIL_NUMBER', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT',\\\n",
    "                        'SCHEDULED_DEPARTURE','DEPARTURE_TIME','DEPARTURE_DELAY',\\\n",
    "                        'SCHEDULED_TIME', 'ELAPSED_TIME','AIR_TIME',\\\n",
    "                         'DISTANCE','SCHEDULED_ARRIVAL', 'ARRIVAL_TIME',\\\n",
    "                         'ARRIVAL_DELAY', 'DIVERTED', 'CANCELLED',\\\n",
    "                        'CANCELLATION_REASON', 'AIR_SYSTEM_DELAY','SECURITY_DELAY', 'AIRLINE_DELAY',\\\n",
    "                        'LATE_AIRCRAFT_DELAY','WEATHER_DELAY']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting historical_wx.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in CSV File\n",
    "csv_file = \"Resources/historical_wx.csv\"\n",
    "df = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming historical_wx.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Unnamed: 0']) # Dropping Column\n",
    "\n",
    "# SQL Throws KeyErrors with Parenthesis and Percentages\n",
    "df = df.rename(columns={'Temperature (F)': 'Temperature F', 'Heat Index (F)': 'Heat Index F', 'Wind Chill (F)': 'Wind Chill F',\n",
    "                       'Dew Point (F)': 'Dew Point F', 'Wind Speed (mph)':'Wind Speed mph', 'Wind Gusts (mph)':'Wind Gusts mph',\n",
    "                       'Precipitation (in)':'Precipitation in', 'Humidity (%)': 'Humidity', 'Visibility (mi)':'Visibility mi',\n",
    "                       'Pressure (mb)':'Pressure mb', 'Cloud Coverage (%)':'Cloud Coverage','Snow Total (cm)':'Snow Total cm'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading airports.csv, flights.csv, and historical_wx.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create connection to engine\n",
    "engine = create_engine(f'postgresql://postgres:{sqlpass}@localhost:5432/airport_weather_delays')\n",
    "connection = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Flights', 'Airports', 'historical_weather']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for tables\n",
    "engine.table_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load flight data into database\n",
    "NY_flights.to_sql(name='Flights', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load airport data into database\n",
    "airport_cleaned.to_sql(name='Airports', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading historical_wx into Database\n",
    "df.to_sql(name='historical_weather', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#close the database connection\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
